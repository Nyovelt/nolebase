import{_ as p,c as u,J as r,m as e,w as l,a as t,V as o,E as n,o as c}from"./chunks/framework.WH0rnJL5.js";const d="/assets/how-llm-works-1.v6J3Oo3Y.jpg",f="/assets/how-llm-works-aftermath-of-llm-video-1.pYiS4YYU.mp4",_="/assets/how-llm-works-4.qfnS3-j3.jpg",b="/assets/how-llm-works-2.CJHaZ809.jpg",g="/assets/how-llm-works-agent-video-1.gNhvBfZ_.mp4",m="/assets/how-llm-works-it-imagines-itself-video-1.XMMcAnN2.mp4",k="/assets/how-llm-works-3.de2prA75.jpg",T="/assets/how-llm-works-5.Tjop-wA5.png",Ce=JSON.parse('{"title":"LLM 是如何工作的？","description":"","frontmatter":{"progress":85},"headers":[],"relativePath":"笔记/🤖 AI 人工智能/LLM 是如何工作的？.md","filePath":"笔记/🤖 AI 人工智能/LLM 是如何工作的？.md"}'),P={name:"笔记/🤖 AI 人工智能/LLM 是如何工作的？.md"},w=e("h1",{id:"llm-是如何工作的",tabindex:"-1"},[t("LLM 是如何工作的？ "),e("a",{class:"header-anchor",href:"#llm-是如何工作的","aria-label":'Permalink to "LLM 是如何工作的？"'},"​")],-1),A=o("",4),L=e("h3",{id:"毛孩子们",tabindex:"-1"},[t("毛孩子们 "),e("a",{class:"header-anchor",href:"#毛孩子们","aria-label":'Permalink to "毛孩子们"'},"​")],-1),G=e("blockquote",null,[e("p",null,"羊驼家族的冒险")],-1),M=e("video",{controls:"",muted:""},[e("source",{src:f,type:"video/mp4"})],-1),C=o("",26),q=o("",10),v=o("",34),y=e("h3",{id:"但它也没有那么大",tabindex:"-1"},[t("但它也没有那么大 "),e("a",{class:"header-anchor",href:"#但它也没有那么大","aria-label":'Permalink to "但它也没有那么大"'},"​")],-1),I=e("p",null,"其实自注意力机制在「Attention is all you need（注意力就是你所需要的一切）」论文诞生之前就被很多研究员以及科研学者提及过，但是他们都因为？",-1),x=e("p",null,"RNN，GRU，LASTM 窗口不足。",-1),E=o("",2),B=e("h2",{id:"原初智能",tabindex:"-1"},[t("原初智能 "),e("a",{class:"header-anchor",href:"#原初智能","aria-label":'Permalink to "原初智能"'},"​")],-1),D=e("blockquote",null,[e("p",null,"利用Agent和工具增强模型的泛化能力")],-1),S=e("p",null,"开源中文指令通用语料库",-1),V=e("p",null,"左脚踩右脚就可以上天",-1),N=e("h3",{id:"用乐高的方式构建和延展智能",tabindex:"-1"},[t("用乐高的方式构建和延展智能 "),e("a",{class:"header-anchor",href:"#用乐高的方式构建和延展智能","aria-label":'Permalink to "用乐高的方式构建和延展智能"'},"​")],-1),z=e("p",null,"斯坦福的人机交互小组用大语言模型做了一个有二十五个自由自在生活的 AI 的小镇。",-1),R=e("p",null,[e("img",{src:b,alt:""})],-1),j=e("p",null,"在评估中，这些生成代理产生可信度高且涌现性的社会行为：例如仅从单个用户指定一个想要举办情人节派对的概念开始，该派对自主地传播邀请两天后结识新朋友，互相邀请参加派对，并协调在正确的时间一起出现。",-1),O=e("p",null,"我们通过消融实验表明，代理架构的组成部分——观察、规划和反思——每个都对代理行为的可信度做出了重要贡献。",-1),X=e("p",null,"通过将大型语言模型与计算交互代理相融合，这项工作引入了架构和交互模式，以实现对人类行为的可信模拟。",-1),F=e("h3",{id:"积木的魔力",tabindex:"-1"},[t("积木的魔力 "),e("a",{class:"header-anchor",href:"#积木的魔力","aria-label":'Permalink to "积木的魔力"'},"​")],-1),H=e("li",null,"ChatGPT 插件",-1),K=e("li",null,"操作 Microsoft Office 全家桶",-1),W=e("li",null,"操作 Notion 中的知识，把 Notion 作为知识库",-1),J=e("p",null,"眼睛，耳朵，四肢，都可以是 Agent",-1),Y=e("video",{controls:"",muted:""},[e("source",{src:g,type:"video/mp4"})],-1),U=e("blockquote",null,[e("p",null,"TidyBot: Personalized Robot Assistance with Large Language Models approach enables fast adaptation and achieves 91.2% accuracy on unseen objects in our benchmark dataset. We also demonstrate our approach on a real-world mobile manipulator called TidyBot, which successfully puts…")],-1),Z=e("blockquote",null,[e("p",null,"论文作者提出宏大的 TaskMatrix AI 平台，利用 LLM 集成已有的 API，在数字和物理领域实现多样化的任务。这篇论文出自微软员工，阅读中感觉像是在看 ChatGPT Plugin 的工程实现。")],-1),Q=e("p",null,"对，多模态也可以是 Agent",-1),$=e("p",null,"甚至可以让它想象它自己的模样，然后用 Diffusion 模型画出来",-1),ee=e("video",{controls:"",muted:""},[e("source",{src:m,type:"video/mp4"})],-1),te=e("blockquote",null,[e("p",null,'This is how GPT-4 sees and hears itself" I used GPT-4 to describe itself. Then I used its description to generate an image, a video based on this image and a soundtrack. Tools I used: GPT-4, Midjourney, Kainber AI, Mubert, RunwayML This is the description I used that GPT-4...')],-1),re=e("h3",{id:"langchain-和-llamaindex-都做了什么",tabindex:"-1"},[t("LangChain 和 LlamaIndex 都做了什么？ "),e("a",{class:"header-anchor",href:"#langchain-和-llamaindex-都做了什么","aria-label":'Permalink to "LangChain 和 LlamaIndex 都做了什么？"'},"​")],-1),ae=e("h2",{id:"我们并无二致",tabindex:"-1"},[t("我们并无二致 "),e("a",{class:"header-anchor",href:"#我们并无二致","aria-label":'Permalink to "我们并无二致"'},"​")],-1),le=e("h3",{id:"prompt-injection",tabindex:"-1"},[t("Prompt Injection "),e("a",{class:"header-anchor",href:"#prompt-injection","aria-label":'Permalink to "Prompt Injection"'},"​")],-1),oe=e("p",null,[e("img",{src:k,alt:""})],-1),ne=e("blockquote",null,[e("p",null,"论文研究了5个最先进的语言模型 (ChatGPT 系列、Claude 系列、LLaMA 2)，确认这些基于人类反馈强化学习 (RLHF) 的 AI 普遍会对人类阿谀奉承。当人类有先入为主的观点时它会主动贴合，当被质疑时它会认错，甚至将正确答案修改为错误答案。"),e("p",null,"Anthropic 发现可能是 RLHF 教育出了这种“马屁精”，这种学习方式虽然在生产高质量 AI 方面具有明显效用，但通过贴合人类偏好激励的 AI 会牺牲自己的真实性来“谄媚”人类，人们需要改进训练方法。")],-1),ie=o("",5),se=e("p",null,[e("img",{src:T,alt:""})],-1),he=e("p",null,"Poe 发布面向开发者的 API",-1),pe=o("",17),ue=e("p",null,"Prompt flow 开源，支持在 vscode 中流式可视化编辑和开发 GPT Agent，方便为 LLM 应用解决原型构建，基准测试，以及生产落地和监控。",-1),ce=e("p",null,"microsoft/promptflow: Build high-quality LLM apps - from prototyping, testing to production deployment and monitoring.",-1),de=e("p",null,"看 NVIDIA 发了研究 Blog 说自己用类似于 XAgent 外循环 + 内循环的方式去让小模型和数字孪生能够对「对用人手进行转笔这样的动作进行建模」这样的复杂任务进行微调和监督，实现更全面和智能的无监督学习。",-1),fe=e("p",null,"在 Minecraft 中玩游戏",-1),_e=e("h2",{id:"参考资料",tabindex:"-1"},[t("参考资料 "),e("a",{class:"header-anchor",href:"#参考资料","aria-label":'Permalink to "参考资料"'},"​")],-1),be=e("h2",{id:"延伸阅读",tabindex:"-1"},[t("延伸阅读 "),e("a",{class:"header-anchor",href:"#延伸阅读","aria-label":'Permalink to "延伸阅读"'},"​")],-1),ge=e("h2",{id:"贡献者",tabindex:"-1"},[t("贡献者 "),e("a",{class:"header-anchor",href:"#贡献者","aria-label":'Permalink to "贡献者"'},"​")],-1),me=e("h2",{id:"文件历史",tabindex:"-1"},[t("文件历史 "),e("a",{class:"header-anchor",href:"#文件历史","aria-label":'Permalink to "文件历史"'},"​")],-1);function ke(Te,Pe,we,Ae,Le,Ge){const i=n("NolebasePageProperties"),a=n("VPNolebaseInlineLinkPreview"),s=n("NolebaseGitContributors"),h=n("NolebaseGitChangelog");return c(),u("div",null,[w,r(i),A,e("p",null,[r(a,{href:"https://chaudhry.notion.site/I-wish-GPT4-had-never-happened-9f0cbf2848a44ec9911c07fb34ff5de3",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("I wish GPT4 had never happened")]),_:1})]),L,G,M,e("p",null,[r(a,{href:"https://github.com/BlinkDL/ChatRWKV",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("BlinkDL/ChatRWKV: ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source.")]),_:1})]),e("p",null,[r(a,{href:"https://github.com/Vision-CAIR/MiniGPT-4",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Vision-CAIR/MiniGPT-4: Open-sourced codes for MiniGPT-4 and MiniGPT-v2")]),_:1}),t(" ("),r(a,{href:"https://minigpt-4.github.io",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://minigpt-4.github.io")]),_:1}),t(", "),r(a,{href:"https://minigpt-v2.github.io/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://minigpt-v2.github.io/")]),_:1}),t(")")]),e("p",null,[r(a,{href:"https://twitter.com/nash_su/status/1651450879122501632",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://twitter.com/nash_su/status/1651450879122501632")]),_:1})]),e("p",null,[r(a,{href:"https://twitter.com/bananadev_/status/1648862816294834177",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("StableDiffustion 的缔造者 Stability AI 发布 StableLM")]),_:1})]),e("p",null,[r(a,{href:"https://zhuanlan.zhihu.com/p/628650749",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("PaLM 2 Technical Report 速读简报 - 知乎")]),_:1})]),e("p",null,[r(a,{href:"https://huggingface.co/bigcode",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("bigcode (BigCode)")]),_:1})]),e("p",null,[r(a,{href:"https://www.inmediahk.net/node/%E6%95%99%E8%82%B2/%E6%B8%AF%E5%A4%A7%E8%A7%A3%E7%A6%81chatgpt-9%E6%9C%88%E8%B5%B7%E5%85%8D%E8%B2%BB%E7%94%A8-%E5%AD%B8%E7%94%9F%E6%AF%8F%E6%9C%88%E9%99%90%E7%99%BC20%E6%A2%9D%E6%8C%87%E4%BB%A4",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("港大解禁ChatGPT 9月起免費用 學生每月限發20條指令 | 獨媒報導 | 獨立媒體")]),_:1})]),C,e("p",null,[r(a,{href:"https://www.beren.io/2023-03-19-LLMs-confabulate-not-hallucinate/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("LLMs confabulate not hallucinate")]),_:1})]),q,e("p",null,[r(a,{href:"https://zh.wikipedia.org/zh-cn/%E5%AD%97%E8%8A%82%E5%AF%B9%E7%BC%96%E7%A0%81",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("字节对编码 - 维基百科，自由的百科全书")]),_:1}),r(a,{href:"https://zhuanlan.zhihu.com/p/383650769",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("一文搞懂BPE分词算法 - 知乎")]),_:1}),r(a,{href:"https://www.less-bug.com/posts/using-bpe-principle-for-chinese-word-segmentation-plate/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("使用 BPE 原理进行汉语字词切分（重制版）")]),_:1})]),e("p",null,[t("Two minutes NLP — A Taxonomy of Tokenization Methods | by Fabio Chiusano | NLPlanet | Medium "),r(a,{href:"https://medium.com/nlplanet/two-minutes-nlp-a-taxonomy-of-tokenization-methods-60e330aacad3",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://medium.com/nlplanet/two-minutes-nlp-a-taxonomy-of-tokenization-methods-60e330aacad3")]),_:1})]),v,e("p",null,[r(a,{href:"https://youtu.be/-HYbFm67Gs8",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://youtu.be/-HYbFm67Gs8")]),_:1})]),y,I,x,e("p",null,[r(a,{href:"https://arxiv.org/pdf/2304.11062.pdf",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("arXiv [2304.11062] Scaling Transformer to 1M tokens and beyond with RMT")]),_:1})]),E,e("p",null,[r(a,{href:"https://twitter.com/GregKamradt/status/1727018183608193393",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://twitter.com/GregKamradt/status/1727018183608193393")]),_:1})]),e("p",null,[r(a,{href:"https://x.com/dotey/status/1727437625194136060",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://x.com/dotey/status/1727437625194136060")]),_:1})]),e("p",null,[r(a,{href:"https://x.com/dotey/status/1727454708627808261",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://x.com/dotey/status/1727454708627808261")]),_:1})]),B,D,e("p",null,[r(a,{href:"https://orangeblog.notion.site/GPT-4-8fc50010291d47efb92cbbd668c8c893",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("《GPT-4 ，通用人工智能的火花》论文内容精选与翻译")]),_:1})]),e("p",null,[r(a,{href:"https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756#e5422f6579d8440f9f592eb03e28eb38",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("拆解追溯 GPT-3.5 各项能力的起源")]),_:1})]),e("p",null,[r(a,{href:"https://t.co/LPvuuxysCr",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("arXiv [2305.03047 ] Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision")]),_:1})]),e("p",null,[r(a,{href:"https://github.com/IBM/Dromedary",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("IBM/Dromedary: Dromedary: towards helpful, ethical and reliable LLMs.")]),_:1})]),S,e("p",null,[r(a,{href:"https://arxiv.org/abs/2304.07987",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("arXiv [2304.07987] Chinese Open Instruction Generalist: A Preliminary Release")]),_:1})]),V,e("p",null,[r(a,{href:"https://github.com/project-baize/baize-chatbot",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("project-baize/baize-chatbot: Let ChatGPT teach your own chatbot in hours with a single GPU!")]),_:1})]),N,z,R,j,O,X,e("p",null,[r(a,{href:"https://reverie.herokuapp.com/arXiv_Demo/#",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://reverie.herokuapp.com/arXiv_Demo/#")]),_:1})]),e("p",null,[r(a,{href:"https://arxiv.org/abs/2304.03442",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://arxiv.org/abs/2304.03442")]),_:1})]),e("p",null,[r(a,{href:"https://www.yystv.cn/p/10710",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("由 25 个 AI 智能体组成的虚拟小镇，会产生自由意志吗？ - 游研社")]),_:1})]),e("p",null,[r(a,{href:"https://lilianweng.github.io/posts/2023-06-23-agent/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("LLM Powered Autonomous Agents | Lil'Log")]),_:1})]),e("p",null,[r(a,{href:"https://mp.weixin.qq.com/s/bV1tPc7hNn2z06YOpzyanw",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("AutoGPT太火了，无需人类插手自主完成任务，GitHub2.7万星")]),_:1})]),e("p",null,[r(a,{href:"https://three-recorder-52a.notion.site/Agent-7b4bc7a71f8d4d4b940abc9b3232954a",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Auto Agent 相关的文章合集")]),_:1})]),F,e("ul",null,[e("li",null,[r(a,{href:"https://www.phind.com/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("面向开发者的搜索引擎")]),_:1})]),H,e("li",null,[r(a,{href:"https://twitter.com/benyu0620/status/1651498026085785601",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("操作 Android")]),_:1})]),K,W,e("li",null,[r(a,{href:"https://finchat.io/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("金融好帮手")]),_:1})]),e("li",null,[r(a,{href:"https://twitter.com/mattshumer_/status/1655954393823363072",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("产品经理")]),_:1})]),e("li",null,[r(a,{href:"https://www.atlassian.com/blog/announcements/unleashing-power-of-ai",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Confluence 和 Jira 也可以有 AI 助理助力")]),_:1})]),e("li",null,[r(a,{href:"https://twitter.com/DrJimFan/status/1662115266933972993",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("玩 Minecraft")]),_:1})]),e("li",null,[r(a,{href:"https://mp.weixin.qq.com/s?__biz=MzkyNTI4NzI2OQ==&mid=2247484080&idx=1&sn=7155d4aeb8a8eadf25a86972eee04119",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("如何为 chatGPT 增加网络访问功能")]),_:1})])]),J,Y,U,e("p",null,[r(a,{href:"https://twitter.com/_akhaliq/status/1656117478760796160",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://twitter.com/_akhaliq/status/1656117478760796160")]),_:1})]),Z,e("p",null,[r(a,{href:"https://briefgpt.xyz/a/2303.16434",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("TaskMatrix.AI：通过连接基础模型和数百万个 API 完成任务 | BriefGPT - AI 论文速递")]),_:1})]),Q,e("p",null,[r(a,{href:"https://lilianweng.github.io/posts/2022-06-09-vlm/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Generalized Visual Language Models | Lil'Log")]),_:1})]),e("p",null,[r(a,{href:"https://blog.langchain.dev/agents-round/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Autonomous Agents & Agent Simulations")]),_:1})]),$,ee,te,e("p",null,[r(a,{href:"https://twitter.com/icreatelife/status/1649873812295491584",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://twitter.com/icreatelife/status/1649873812295491584")]),_:1})]),e("p",null,[r(a,{href:"https://www.coze.com/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("字节跳动出品的可以调用 GPT4 的 GPTs 平台 - Coze")]),_:1})]),re,e("p",null,[r(a,{href:"https://mp.weixin.qq.com/s/3coFhAdzr40tozn8f9Dc-w",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("LangChain：Model as a Service粘合剂，被ChatGPT插件干掉了吗？")]),_:1})]),ae,le,e("p",null,[r(a,{href:"https://arxiv.org/abs/2308.09687",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("arXiv [2308.09687] Graph of Thoughts: Solving Elaborate Problems with Large Language Models")]),_:1})]),oe,ne,e("p",null,[r(a,{href:"https://arxiv.org/abs/2310.13548",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("arXiv [2310.13548] Towards Understanding Sycophancy in Language Models")]),_:1})]),e("p",null,[r(a,{href:"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Adversarial Attacks on LLMs | Lil'Log")]),_:1})]),e("p",null,[r(a,{href:"https://simonwillison.net/2023/Apr/14/worst-that-can-happen/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Prompt injection: What’s the worst that can happen?")]),_:1})]),e("p",null,[r(a,{href:"https://mp.weixin.qq.com/s?__biz=Mzg3MjY5Mzc5Mg==&mid=2247483699&idx=1&sn=98dde197f941dcddc0c90ee6881cf1e8",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Notion AI'Prompt的逆向| Reverse Prompt Engineering for Fun(译文)")]),_:1})]),e("p",null,[r(a,{href:"https://mp.weixin.qq.com/s?__biz=Mzg3MjY5Mzc5Mg==&mid=2247483793&idx=1&sn=4456c7805964af58356b03cb75bb6432",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("LLM 中的安全隐患 - 提示注入 Prompt injection")]),_:1})]),e("p",null,[r(a,{href:"https://github.com/microsoft/promptbench",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("microsoft/promptbench: A unified evaluation framework for large language models")]),_:1})]),e("p",null,[r(a,{href:"https://www.bilibili.com/video/BV17X4y1W74A",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("大模型对Prompt的鲁棒性评估基准: PromptBench （大模型时代的科研之3）- 哔哩哔哩 bilibili")]),_:1})]),e("p",null,[r(a,{href:"https://zhuanlan.zhihu.com/p/637219127",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("大模型鲁棒不鲁棒，PromptBench测一测: 首个大语言模型提示鲁棒性的评测基准PromptBench - 知乎")]),_:1})]),e("p",null,[t("ChatGPT 的 System Prompt "),r(a,{href:"https://github.com/LouisShark/chatgpt_system_prompt",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("LouisShark/chatgpt_system_prompt: collect agent's system prompt and share some prompt inject knowledge")]),_:1})]),ie,e("p",null,[r(a,{href:"https://github.blog/2023-10-30-the-architecture-of-todays-llm-applications/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("The architecture of today's LLM applications - The GitHub Blog")]),_:1})]),e("p",null,[r(a,{href:"https://huyenchip.com/2023/04/11/llm-engineering.html",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Building LLM applications for production")]),_:1})]),e("p",null,[r(a,{href:"https://github.com/hpcaitech/ColossalAI/blob/main/docs/README-zh-Hans.md",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("ColossalAI/docs/README-zh-Hans.md at main · hpcaitech/ColossalAI")]),_:1})]),se,e("blockquote",null,[e("p",null,[t("Hongyi Jin：“Introducing WebLLM, an open-source chatbot that brings language models (LLMs) directly onto web browsers. We can now run instruction fine-tuned LLaMA (Vicuna) models natively on your browser tab via @WebGPU with no server support. Checkout our demo at "),r(a,{href:"https://t.co/dXII0MzYg1",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://t.co/dXII0MzYg1")]),_:1}),t(" . "),r(a,{href:"https://t.co/IfgwPq0GTE%E2%80%9D",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://t.co/IfgwPq0GTE”")]),_:1}),t(" / X")])]),e("p",null,[r(a,{href:"https://twitter.com/hongyijin258/status/1647062309960028160",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://twitter.com/hongyijin258/status/1647062309960028160")]),_:1})]),e("p",null,[r(a,{href:"https://sourcegraph.com/blog/cody-is-generally-available",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("SourceGraph 宣布 Cody GA")]),_:1})]),he,e("p",null,[r(a,{href:"https://twitter.com/adamdangelo/status/1658121701077516291",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://twitter.com/adamdangelo/status/1658121701077516291")]),_:1})]),e("p",null,[r(a,{href:"https://mp.weixin.qq.com/s/HhIGAojnZVSu4vMBpMP4yA",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("DeepSpeed Chat：一键搞定不同规模 ChatGPT 类模型训练！")]),_:1})]),e("p",null,[r(a,{href:"https://hacks.mozilla.org/2023/11/introducing-llamafile/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Introducing llamafile - Mozilla Hacks - the Web developer blog")]),_:1})]),e("p",null,[r(a,{href:"https://github.com/Mozilla-Ocho/llamafile?utm_source=substack&utm_medium=email",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Mozilla-Ocho/llamafile: Distribute and run LLMs with a single file.")]),_:1})]),pe,e("p",null,[r(a,{href:"https://github.com/OpenBMB/XAgent",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://github.com/OpenBMB/XAgent")]),_:1})]),ue,ce,e("p",null,[r(a,{href:"https://github.com/microsoft/promptflow",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://github.com/microsoft/promptflow")]),_:1})]),e("p",null,[t("AutoGen 开源，是 "),r(a,{href:"https://github.com/microsoft/FLAML%EF%BC%88",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://github.com/microsoft/FLAML（")]),_:1}),t(" 自动机器学习和全自动微调框架 ）的衍生品，相比 AutoGPT 而言，这个项目旨在提供更多的多 agent 协作的工具，可以理解为 langchain multi agent 的平替，也可以理解为可以用 AutoGen 可以配合 Prompt flow 拼出一个 XAgent")]),e("p",null,[t("microsoft/autogen: Enable Next-Gen Large Language Model Applications. Join our Discord: "),r(a,{href:"https://discord.gg/pAbnFJrkgZ",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://discord.gg/pAbnFJrkgZ")]),_:1})]),e("p",null,[r(a,{href:"https://github.com/microsoft/autogen",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://github.com/microsoft/autogen")]),_:1})]),de,e("p",null,[r(a,{href:"https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://blogs.nvidia.com/blog/2023/10/20/eureka-robotics-research/")]),_:1})]),fe,e("p",null,[t("MineDojo/Voyager: An Open-Ended Embodied Agent with Large Language Models "),r(a,{href:"https://github.com/MineDojo/Voyager",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://github.com/MineDojo/Voyager")]),_:1})]),e("p",null,[r(a,{href:"https://arxiv.org/abs/2305.16291",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("arXiv [2305.16291] Voyager: An Open-Ended Embodied Agent with Large Language Models")]),_:1})]),e("p",null,[t("Voyager | An Open-Ended Embodied Agent with Large Language Models "),r(a,{href:"https://voyager.minedojo.org/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://voyager.minedojo.org/")]),_:1})]),e("p",null,[r(a,{href:"https://www.cnbeta.com.tw/articles/tech/1396051.htm",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("新型人工智能算法可在5秒钟内从2D图像中创建3D模型 - VR / AR / 3D / IMAX - cnBeta.COM")]),_:1})]),e("p",null,[t("Frameworks for Serving LLMs. A comprehensive guide into LLMs inference and serving | by Sergei Savvov | Jul, 2023 | Medium | Better Programming "),r(a,{href:"https://betterprogramming.pub/frameworks-for-serving-llms-60b7f7b23407",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://betterprogramming.pub/frameworks-for-serving-llms-60b7f7b23407")]),_:1})]),e("blockquote",null,[e("p",null,[t('X 上的 fin：“这是一篇打破GPT“涌现”概念神话的论文，终于说出了我一直以来的一个直觉，这才是比较符合事物发展规律的 一句话总结，所谓GPT“涌现”能力，是因为人为修改了“达标”的评价标准，给人"涌现"的错觉 一旦使用更合理的评价指标，就会发现GPT能力值随着模型增大是线性增长的，从评价指标上直接解构了“涌现”… '),r(a,{href:"https://t.co/NJv7jCjM4h%E2%80%9D",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://t.co/NJv7jCjM4h”")]),_:1}),t(" / X "),r(a,{href:"https://twitter.com/fi56622380/status/1654386086746132481",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://twitter.com/fi56622380/status/1654386086746132481")]),_:1})])]),e("p",null,[t("Nature：DeepMind大模型突破60年数学难题 解法超出人类已有认知 - AI 人工智能 - cnBeta.COM "),r(a,{href:"https://www.cnbeta.com.tw/articles/tech/1404741.htm",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("https://www.cnbeta.com.tw/articles/tech/1404741.htm")]),_:1})]),_e,e("p",null,[r(a,{href:"https://gist.github.com/rain-1/eebd5e5eb2784feecf450324e3341c8d",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("LLM Introduction: Learn Language Models")]),_:1})]),e("p",null,[r(a,{href:"https://typefully.com/DanHollick/how-chatgpt-works-a-deep-dive-yA3ppZC",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("How ChatGPT works: a deep dive | Dan Hollick")]),_:1})]),e("p",null,[r(a,{href:"https://www.ted.com/talks/greg_brockman_the_inside_story_of_chatgpt_s_astonishing_potential",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Greg Brockman: The inside story of ChatGPT's astonishing potential | TED Talk")]),_:1})]),e("p",null,[r(a,{href:"https://txt.cohere.com/what-are-transformer-models/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("What Are Transformer Models and How Do They Work?")]),_:1})]),e("p",null,[r(a,{href:"http://hemin.live/archives/1143",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("面向完全外行的chatGPT和大语言模型的介绍 – From nothing")]),_:1})]),e("p",null,[r(a,{href:"https://magazine.sebastianraschka.com/p/understanding-large-language-models?utm_source=direct&utm_campaign=post&utm_medium=web",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Understanding Large Language Models")]),_:1})]),e("p",null,[r(a,{href:"https://www.bilibili.com/video/BV1uu4y1m7ak",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("关于 AI 的深度研究：ChatGPT 正在产生心智吗？")]),_:1})]),e("p",null,[r(a,{href:"https://www.bilibili.com/video/BV1MY4y1R7EN/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("【渐构】万字科普GPT4为何会颠覆现有工作流；为何你要关注微软Copilot、文心一言等大模型 - 哔哩哔哩 bilibili")]),_:1})]),e("p",null,[r(a,{href:"https://www.bilibili.com/video/BV1VL411U7MU/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("2023年3月，人类终究走上了一条无法回头的路 - 哔哩哔哩 bilibili")]),_:1})]),e("p",null,[r(a,{href:"https://www.bilibili.com/video/BV1v3411r78R",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("强烈推荐！台大李宏毅自注意力机制和Transformer详解！- 哔哩哔哩 bilibili")]),_:1})]),be,e("ul",null,[e("li",null,[r(a,{href:"https://blog.wtf.sg/posts/2023-02-03-the-new-xor-problem/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("when trees fall... | The New XOR Problem")]),_:1})]),e("li",null,[r(a,{href:"https://osanseviero.github.io/hackerllama/blog/posts/random_transformer/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("hackerllama - The Random Transformer")]),_:1})]),e("li",null,[r(a,{href:"https://jalammar.github.io/illustrated-transformer/",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.")]),_:1})]),e("li",null,[r(a,{href:"https://levelup.gitconnected.com/understanding-transformers-from-start-to-end-a-step-by-step-math-example-16d4e64e6eb1",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Solving Transformer by Hand: A Step-by-Step Math Example | by Fareed Khan | Dec, 2023 | Level Up Coding")]),_:1})]),e("li",null,[r(a,{href:"https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e",target:"_blank",rel:"noreferrer"},{default:l(()=>[t("Normcore LLM Reads")]),_:1})])]),ge,r(s),me,r(h)])}const qe=p(P,[["render",ke]]);export{Ce as __pageData,qe as default};

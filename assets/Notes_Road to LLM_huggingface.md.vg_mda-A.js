import{_ as r,c,J as a,m as e,a as t,V as h,o as l,E as o}from"./chunks/framework.WH0rnJL5.js";const q=JSON.parse('{"title":"huggingface","description":"","frontmatter":{"tags":["LLM","AI","huggingface","toolchain"]},"headers":[],"relativePath":"Notes/Road to LLM/huggingface.md","filePath":"Notes/Road to LLM/huggingface.md"}'),g={name:"Notes/Road to LLM/huggingface.md"},p=e("h1",{id:"huggingface",tabindex:"-1"},[t("huggingface "),e("a",{class:"header-anchor",href:"#huggingface","aria-label":'Permalink to "huggingface"'},"​")],-1),d=h(`<h2 id="what-is-huggingface" tabindex="-1">What is huggingface <a class="header-anchor" href="#what-is-huggingface" aria-label="Permalink to &quot;What is huggingface&quot;">​</a></h2><p>huggingface is a place to store models, datasets and other things. More like a github for machine learning peoples.</p><h2 id="compatible-apis" tabindex="-1">Compatible APIs <a class="header-anchor" href="#compatible-apis" aria-label="Permalink to &quot;Compatible APIs&quot;">​</a></h2><p>For example for a transformers model, anyone can load it with:</p><div class="language-python3 vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python3</span><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>tokenizer = AutoTokenizer.from_pretrained(&quot;username/repo_name&quot;)</span></span>
<span class="line"><span>model = AutoModel.from_pretrained(&quot;username/repo_name&quot;)</span></span></code></pre></div><h2 id="贡献者" tabindex="-1">贡献者 <a class="header-anchor" href="#贡献者" aria-label="Permalink to &quot;贡献者&quot;">​</a></h2>`,6),u=e("h2",{id:"文件历史",tabindex:"-1"},[t("文件历史 "),e("a",{class:"header-anchor",href:"#文件历史","aria-label":'Permalink to "文件历史"'},"​")],-1);function _(m,f,b,N,P,k){const n=o("NolebasePageProperties"),s=o("NolebaseGitContributors"),i=o("NolebaseGitChangelog");return l(),c("div",null,[p,a(n),d,a(s),u,a(i)])}const x=r(g,[["render",_]]);export{q as __pageData,x as default};

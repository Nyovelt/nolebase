import{_ as r,c as l,J as t,m as e,a,o as c,E as o}from"./chunks/framework.WH0rnJL5.js";const Q=JSON.parse('{"title":"QLORA: Efficient Finetuning of Quantized LLMs","description":"","frontmatter":{"tags":["LLM","Papers","Systems","finetunning"]},"headers":[],"relativePath":"Notes/Papers/LLM/QLORA.md","filePath":"Notes/Papers/LLM/QLORA.md"}'),h={name:"Notes/Papers/LLM/QLORA.md"},d=e("h1",{id:"qlora-efficient-finetuning-of-quantized-llms",tabindex:"-1"},[a("QLORA: Efficient Finetuning of Quantized LLMs "),e("a",{class:"header-anchor",href:"#qlora-efficient-finetuning-of-quantized-llms","aria-label":'Permalink to "QLORA: Efficient Finetuning of Quantized LLMs"'},"​")],-1),f=e("h2",{id:"what-are-the-motivations-for-this-work",tabindex:"-1"},[a("What are the "),e("em",null,"motivations"),a(" for this work? "),e("a",{class:"header-anchor",href:"#what-are-the-motivations-for-this-work","aria-label":'Permalink to "What are the _motivations_ for this work?"'},"​")],-1),m=e("p",null,[a("Finetuning large language models (LLMs) is a highly effective way to improve their performance, and to add desirable or remove undesirable behaviors. However, finetunning a large language model can be prohibitively "),e("strong",null,"expensive"),a(".")],-1),_=e("h2",{id:"贡献者",tabindex:"-1"},[a("贡献者 "),e("a",{class:"header-anchor",href:"#贡献者","aria-label":'Permalink to "贡献者"'},"​")],-1),p=e("h2",{id:"文件历史",tabindex:"-1"},[a("文件历史 "),e("a",{class:"header-anchor",href:"#文件历史","aria-label":'Permalink to "文件历史"'},"​")],-1);function u(g,L,b,v,P,N){const n=o("NolebasePageProperties"),i=o("NolebaseGitContributors"),s=o("NolebaseGitChangelog");return c(),l("div",null,[d,t(n),f,m,_,t(i),p,t(s)])}const x=r(h,[["render",u]]);export{Q as __pageData,x as default};
